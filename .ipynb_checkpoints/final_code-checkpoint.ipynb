{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02c3a932-a918-4358-906e-08ac58ab87a5",
   "metadata": {},
   "source": [
    "# Regression Modeling \n",
    "- NEED TO ADDRESS THE PAGINATION?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9695788c-0bec-4624-9c47-e26a280341ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret import key\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9fae9f-cc7a-49fa-ba25-3d3ec220bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = 'us-state-abbreviations.txt'\n",
    "with open(FILENAME, 'r') as file:\n",
    "    # Read the file contents and split by lines\n",
    "    state_abbreviations = [line.strip() for line in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b885330b-ee10-498a-96b8-e7799a8c2f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_st_df(state, student_size=1000):\n",
    "    # Base URL for the College Scorecard API\n",
    "    url = \"https://api.data.gov/ed/collegescorecard/v1/schools\"\n",
    "    \n",
    "    # Your API key (replace with your own key)\n",
    "    api_key = key\n",
    "    \n",
    "    fields = ['school.name',\n",
    "              # ---- just added this feature! \n",
    "              'school.region_id',\n",
    "              'latest.student.size',\n",
    "              'school.state',\n",
    "              'latest.admissions.admission_rate.overall',\n",
    "              'latest.admissions.sat_scores.average.overall',\n",
    "              'latest.admissions.act_scores.midpoint.cumulative',\n",
    "              'latest.admissions.test_requirements',\n",
    "              f'student.size__range={student_size}..']\n",
    "    \n",
    "    params = {\n",
    "        'api_key': api_key,\n",
    "        'school.state': state, \n",
    "        'fields': ','.join(fields), \n",
    "        'page': 0,  # Page number for pagination\n",
    "\n",
    "        'per_page': 100  # Number of records per page (you can adjust this)\n",
    "    }\n",
    "    \n",
    "    # Send the GET request\n",
    "    response = requests.get(url, params=params)\n",
    "    state_data = response.json()['results']\n",
    "\n",
    "    return state_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab45cc9f-bc2a-4dce-ab3d-0bb3e12deb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_states_data(key, st_list):\n",
    "    \"\"\" Iterates through all states and collects the data for each\n",
    "    Params:\n",
    "    - key = API key\n",
    "    Returns:\n",
    "    A dictionary with states as keys and corresponding school data as values \"\"\"\n",
    "    \n",
    "    # Dictionary to store data for all states\n",
    "    all_states_data = []\n",
    "    \n",
    "    # Loop through all states\n",
    "    for state in st_list:\n",
    "        print(f\"Retrieving data for {state}...\")\n",
    "        state_data = get_st_df(state)\n",
    "        \n",
    "        all_states_data.append(state_data)\n",
    "        \n",
    "    # # Combine all state data into a single DataFrame\n",
    "    # combined_df = pd.concat(all_states_data, ignore_index=True)\n",
    "    return all_states_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b3322-83b0-4655-844b-3117c1a1de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather all the state data!\n",
    "all_states = get_all_states_data(key, state_abbreviations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5500cb4-6bdd-4d94-a726-adb1cb8b708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_data = [school for state_data in all_states for school in state_data]\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(flattened_data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb1fa8-a934-4b22-935b-34fdd43998ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- analyze NaN value count \n",
    "nan_count = df.isna().sum()\n",
    "nan_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8407b6a-abc5-4a40-95dc-b42d26f0fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- need to rename the column names \n",
    "df.rename(columns={\n",
    "    'latest.student.size': 'size',\n",
    "    'latest.admissions.admission_rate.overall': 'admin_rate',\n",
    "    'latest.admissions.sat_scores.average.overall': 'avg_sat',\n",
    "    'latest.admissions.act_scores.midpoint.cumulative': 'midpoint_act',\n",
    "    'latest.admissions.test_requirements': 'test_requirements',\n",
    "    'school.name': 'name',\n",
    "    'school.state': 'state',\n",
    "    'school.region_id': 'region_id'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ca72db-7c9f-4de8-b690-076b72594ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- convert numerical requirements to strings \n",
    "test_labels = {\n",
    "        0: 'Not Required',\n",
    "        1: 'Required',\n",
    "        2: 'Recommended',\n",
    "        3: 'Niether Rec. or Req.',\n",
    "        4: 'Not Known'}\n",
    "\n",
    "df['test_requirements'] = df['test_requirements'].map(\n",
    "    lambda x: test_labels.get(x, 'Considered but not Req.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b332df-3b3e-44a1-842a-02cb4c589a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- do hot-encoding instead of mapping numbers \n",
    "df_encoded = pd.get_dummies(df['test_requirements'], prefix='test', dtype=float)\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc59348-81dd-4963-a49e-18728439a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the dataframes together! \n",
    "df_merged = pd.concat([df, df_encoded], axis=1)\n",
    "\n",
    "# don't need the test_requirements column anymore\n",
    "df_merged.drop(\"test_requirements\", axis=1)\n",
    "\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e26ab6-6da0-4d54-85f1-dee54ecc148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_average(df, state, column):\n",
    "    \"\"\" add in docstring \"\"\"\n",
    "    if state is None:\n",
    "        print(\"State is None.\")\n",
    "        return None\n",
    "    state_avg = df.groupby('state')[column].mean()\n",
    "    return state_avg.get(state, None)\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    \"\"\" add in docstring \"\"\"\n",
    "    for index, row in df.iterrows():\n",
    "        for column in ['admin_rate', 'avg_sat', 'midpoint_act']:\n",
    "            if pd.isna(row[column]):\n",
    "                avg = get_state_average(df, row['state'], column)\n",
    "                df.at[index, column] = avg\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a3f99f-3304-4e17-94f4-80dd204c668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nan(data, drop=False):\n",
    "    \"\"\" add in docstring \"\"\"\n",
    "    if drop is True:\n",
    "        drop_df = data.dropna()\n",
    "    else: \n",
    "        # drop rows that have more than 1 NaN value\n",
    "        drop_df = data.dropna(thresh=len(data.columns) - 1)\n",
    "        # fill with state averages\n",
    "        drop_df = fill_missing_values(drop_df)\n",
    "    return drop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a77d10-3563-4f79-b651-797ce1eb364e",
   "metadata": {},
   "source": [
    "# Regression Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e7e071-dc0a-40e2-b5e3-0e279c25cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias_column(X):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X (array): can be either 1-d or 2-d\n",
    "    \n",
    "    Returns:\n",
    "        Xnew (array): the same array, but 2-d with a column of 1's in the first spot\n",
    "    \"\"\"\n",
    "    \n",
    "    # If the array is 1-d\n",
    "    if len(X.shape) == 1:\n",
    "        Xnew = np.column_stack([np.ones(X.shape[0]), X])\n",
    "    \n",
    "    # If the array is 2-d\n",
    "    elif len(X.shape) == 2:\n",
    "        bias_col = np.ones((X.shape[0], 1))\n",
    "        Xnew = np.hstack([bias_col, X])\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Input array must be either 1-d or 2-d\")\n",
    "\n",
    "    return Xnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822b401-39d3-4362-97f2-697d7829ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_of_best_fit(X, y):\n",
    "    \"\"\" Args: \n",
    "            X (array): either 1d or 2d with the predictor values \n",
    "            y (array): 1d and corresponding response values to 'X'\n",
    "        Returns: \n",
    "            m (vector): vector with the slope and intercept term of the line of best fit\"\"\"\n",
    "    # first call the add_bias_column for line of best fit calculation \n",
    "    Xnew = add_bias_column(X)\n",
    "    \n",
    "    # get the inverse of X transpose \n",
    "    XtXinv = np.linalg.inv(np.matmul(Xnew.T, Xnew))\n",
    "    \n",
    "    # get the vector with the slope and intercept term\n",
    "    m = np.matmul(XtXinv, np.matmul(Xnew.T, y))\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522bfd84-0d30-4491-b915-1bdca2e0de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg_predict(Xnew, ynew, m):\n",
    "    \"\"\" Args: \n",
    "            Xnew (array): 1d or 2d with all predictor values, not including bias term\n",
    "            ynew (array): 1d with all corresponding response values to 'Xnew'\n",
    "            m (array): 1d array that contains the coefficents form the line_of_best_fit function\n",
    "        Returns:\n",
    "            result_dict (dct): A dct with 4 key-value pairs - ypreds, resids, mse, and r2\"\"\"\n",
    "    \n",
    "    # add bias column \n",
    "    Xnew = add_bias_column(Xnew)\n",
    "\n",
    "    # fetch all the calculations\n",
    "    ypreds = np.matmul(Xnew, m)\n",
    "\n",
    "    resids = ynew - ypreds\n",
    "    \n",
    "    mse = np.mean(resids ** 2)\n",
    "\n",
    "    # use of sklearn built-in r2_score function \n",
    "    r2 = r2_score(ynew, ypreds)\n",
    "\n",
    "    # set up key-value pairs in the resulting dictionary \n",
    "    result_dict = {'ypreds': ypreds,\n",
    "                  'resids': resids,\n",
    "                  'mse': mse,\n",
    "                  'r2': r2}\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e02e24-bf2e-4095-9da4-b34480469962",
   "metadata": {},
   "source": [
    "## Different Versions \n",
    "1. Multiple regression w/ categorical variable \n",
    "2. Multiple regression w/ PCA\n",
    "3. Polynomial regression (Multiple) | Do I need to also use PCA here? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1513c7-0219-4272-ac4e-f744a1ee47ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address NaN Values here1\n",
    "drop_df = clean_nan(merged_df)\n",
    "drop_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb451bcf-c9b2-4933-9902-f443bf6735b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ CHECK THE SHAPE!\n",
    "drop_df.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b8087-6df8-4234-8876-c4d312186a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count = drop_df.isna().sum()\n",
    "nan_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0c22c3-e889-466c-ba86-e2ac2dfe7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # look at the rows with NaN values\n",
    "# rows_with_nan = drop_df[drop_df.isna().any(axis=1)]\n",
    "# rows_with_nan"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14aec20a-750e-4300-a184-114c8aed1cc8",
   "metadata": {},
   "source": [
    "# now replace the NaN values in the drop df with averages \n",
    "fill_df = fill_missing_values(drop_df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4dbe04a3-78d5-49d5-85dc-e399fc958d81",
   "metadata": {},
   "source": [
    "nan_count = drop_df.isna().sum()\n",
    "nan_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34274cde-e2e9-4a90-abea-e6171a5d6ca2",
   "metadata": {},
   "source": [
    "### I. Check with Simple Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53766f59-196f-42d5-a0e6-4f3c10717fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS-FOLD VALIDATION\n",
    "X = drop_df['avg_sat']\n",
    "y = drop_df['admin_rate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# now fit model using line_of_best_fit function\n",
    "m_train = line_of_best_fit(X_train, y_train)\n",
    "\n",
    "# use test data to evaulate the model using the linreg_predict function, get \"m\" param from fitting the model above \n",
    "results = linreg_predict(X_test, y_test, m_train)\n",
    "\n",
    "print(f\"MSE: {results['mse']}, R^2: {results['r2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54246b3-e72f-4df6-8f5f-3fc89b28ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the regression model to the full data set \n",
    "m_full = line_of_best_fit(drop_df[\"avg_sat\"], drop_df[\"admin_rate\"])\n",
    "slope = m_full[1]\n",
    "intercept = m_full[0]\n",
    "\n",
    "\n",
    "X = drop_df[\"avg_sat\"]\n",
    "\n",
    "y_pred = slope * X + intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776da82a-e424-4c9f-8cb3-adf06c8b19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INTIAL PLOT to see fit of the simple regression \n",
    "plt.scatter(X, drop_df[\"admin_rate\"], label='data', alpha=0.5)\n",
    "\n",
    "plt.plot(X, y_pred, color='black',label='linear fit')\n",
    "\n",
    "plt.xlabel(\"Average SAT Score\")\n",
    "plt.ylabel(\"Admission Rate\")\n",
    "plt.title(\"Simple Regression Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5942c6f6-61c0-487b-93b6-ee507e2b8349",
   "metadata": {},
   "source": [
    "Still, the performance of the **simple linear regression model is sub-optimal** with the improved handling of NaN values. This further motivates the use of multiple and polynomial regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278ae43c-e5a5-41ff-a8d6-effee2960554",
   "metadata": {},
   "source": [
    "### Multiple regression w/ categorical variable \n",
    "- Need to double check this variable naming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc0776-3215-474e-bfbd-48d8fc40b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9885970a-be33-4fb4-94de-8797a44bc028",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count = drop_df.isna().sum()\n",
    "nan_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3eef56-0b61-4880-929f-521b4d6e49f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_list = ['size', 'avg_sat', 'midpoint_act','test_Considered but not Req.',\n",
    "#        'test_Niether Rec. or Req.', 'test_Not Required', 'test_Required']\n",
    "\n",
    "# X_multi = drop_df[feat_list]\n",
    "# y = drop_df['admin_rate']\n",
    "\n",
    "# # scale the continuous features using standardization\n",
    "# df_scaled = pd.DataFrame()\n",
    "\n",
    "# continuous_feat = ['size', 'avg_sat', 'midpoint_act']\n",
    "\n",
    "# for feat in continuous_feat:\n",
    "#     df_scaled[f'{feat}_scaled'] = ((X_multi[feat] - X_multi[feat].mean()) / X_multi[feat].std())\n",
    "\n",
    "# df_scaled = pd.concat([df_scaled, drop_df[['test_Considered but not Req.',\n",
    "#        'test_Niether Rec. or Req.', 'test_Not Required', 'test_Required']]], axis=1)\n",
    "\n",
    "# # convert dataframe to numpy array \n",
    "# X_scaled = np.array(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6bd2db-8f01-44ca-8d84-d6c2ec88ba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to take a different approach to standarization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instantiate StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "feat_list = ['size', 'avg_sat', 'midpoint_act','test_Considered but not Req.',\n",
    "       'test_Niether Rec. or Req.', 'test_Not Required', 'test_Required']\n",
    "\n",
    "X_multi = drop_df[feat_list]\n",
    "\n",
    "# Standardize the data\n",
    "standardized_features = scaler.fit_transform(X_multi)\n",
    "\n",
    "# Convert back to DataFrame for interpretability\n",
    "standardized_df = pd.DataFrame(standardized_features, columns=X_multi.columns)\n",
    "\n",
    "X_scaled = np.array(standardized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c063bc30-92c6-438f-b7fb-1d1ae27c7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9182edb-3af6-41f5-9b36-6917096d1a77",
   "metadata": {},
   "source": [
    "The cell below does not run properly bc it is single-cross fold and there are some outliers -> \"Considered but not Req.\" and \"Required\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8288daca-cb90-493f-a0ea-a61cf54823f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CROSS VALIDATION\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # now fit model using line_of_best_fit function\n",
    "# m_multi = line_of_best_fit(X_train, y_train)\n",
    "\n",
    "# # use test data to evaulate the model using the linreg_predict function, get \"m\" param from fitting the model above \n",
    "# results = linreg_predict(X_test, y_test, m_multi)\n",
    "\n",
    "# print(f\"MSE: {results['mse']}, R^2: {results['r2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813602a1-2906-4943-9eb5-65038eeff86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- REORGANIZE THIS CODE!\n",
    "def get_ypreds(Xnew, m):\n",
    "    \"\"\"add in docstring! \"\"\"\n",
    "    # add bias column \n",
    "    Xnew = add_bias_column(Xnew)\n",
    "\n",
    "    # fetch all the calculations\n",
    "    ypreds = np.matmul(Xnew, m)\n",
    "    \n",
    "    return ypreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54baaca-6454-4aee-901a-9f184a44bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn this code block into a function \n",
    "def loo_cv(X_new, y):\n",
    "    \"\"\" add in docstring here! \"\"\"\n",
    "    y_preds = np.empty(len(y))\n",
    "\n",
    "    # this is extracted from the linreg_predict function \n",
    "\n",
    "    # loop through each observation\n",
    "    for obs in range(len(y)):\n",
    "        # the below excludes the single row/true y belonging to obs as well as the bias column\n",
    "        loocv_trainX = np.concatenate((X_new[:obs, 1].reshape(-1,1), X_new[obs+1:, 1].reshape(-1,1)))\n",
    "        loocv_trainy = np.concatenate((y[:obs], y[obs+1:]))\n",
    "\n",
    "        m = line_of_best_fit(loocv_trainX, loocv_trainy)\n",
    "\n",
    "        # Xnew = add_bias_column(X_new) # --- this might be unecessary \n",
    "        # ypreds = np.matmul(Xnew, m)\n",
    "\n",
    "        # y_preds[obs] = linreg_predict(X_new[obs,1].reshape(-1,1), None, m)['ypreds'][0]\n",
    "        y_preds[obs] = get_ypreds(X_new[obs,1].reshape(-1,1), m)[0]\n",
    "\n",
    "    # save the scores \n",
    "    r_squared = r2_score(y, y_preds)\n",
    "    mse = ((y - y_preds)**2).mean()\n",
    "    \n",
    "    return r_squared, mse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c4c7fe-0c39-4d05-a32d-3763142b329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squaredA, mseA = loo_cv(X_scaled, y)\n",
    "print(f\"R^2: {r_squaredA}, MSE: {mseA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99340dd4-6b09-498c-8ec1-b170f3d5e635",
   "metadata": {},
   "source": [
    "### Multiple regression w/ PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4d46e-788f-4634-a528-9bd49c7a36d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list2 = ['avg_sat', 'midpoint_act', 'size']\n",
    "\n",
    "X_multi = drop_df[feat_list2]\n",
    "\n",
    "# scale the features using standardization\n",
    "df_scaled = pd.DataFrame()\n",
    "\n",
    "for feat in X_multi.columns:\n",
    "    df_scaled[f'{feat}_scaled'] = ((X_multi[feat] - X_multi[feat].mean()) / X_multi[feat].std())\n",
    "\n",
    "# convert dataframe to numpy array \n",
    "X_scaled = np.array(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d3c0b-4c8d-403f-b1f5-942fb560503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA implementation \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 2)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf22d426-5a1e-4031-a1df-e182ffd44d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS VALIDATION\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# now fit model using line_of_best_fit function\n",
    "m_multi_pca = line_of_best_fit(X_train, y_train)\n",
    "\n",
    "# use test data to evaulate the model using the linreg_predict function, get \"m\" param from fitting the model above \n",
    "results = linreg_predict(X_test, y_test, m_multi_pca)\n",
    "\n",
    "print(f\"MSE: {results['mse']}, R^2: {results['r2']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368c9680-32b6-49b3-af44-a7a2fa999dee",
   "metadata": {},
   "source": [
    "Using PCA does not improve the performance of the model! When used n_components = 1, R^2 is **negative**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cebac2-4112-40ce-afea-21b4e1c28520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOO-CV\n",
    "r_squaredB, mseB = loo_cv(X_pca, y)\n",
    "print(f\"R^2: {r_squaredB}, MSE: {mseB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627c97ae-23e1-4b16-a2ae-b94f33a099b0",
   "metadata": {},
   "source": [
    "The R^2 using LOO-CV is signifcantly smaller! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87cc04f-e34d-42c1-9297-bd1edfd9edfc",
   "metadata": {},
   "source": [
    "## Multiple Polynomial Regression\n",
    "- still should play around with the degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d0fab4-b1cf-4370-97d9-e4d3f6c42d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# ------- this is a single poly regression test \n",
    "X_scores = np.array(drop_df['avg_sat']).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2e9360-f058-4276-95a1-a6542daf0b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the cubic model\n",
    "poly = PolynomialFeatures(3)\n",
    "X_poly = poly.fit_transform(X_scores)\n",
    "\n",
    "# drop the last bias column \n",
    "X_poly = X_poly[:, 1:]\n",
    "X_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffd2a0c-2433-4c49-b4ee-90e42a1c33dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform single-fold cross validation \n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_poly, drop_df['admin_rate'], test_size=0.30, random_state=42)\n",
    "\n",
    "# fit to training data \n",
    "m_poly = line_of_best_fit(Xtrain, ytrain)\n",
    "\n",
    "# pass testing data \n",
    "poly_rlst = linreg_predict(Xtest, ytest, m_poly)\n",
    "\n",
    "\n",
    "print(f\"MSE: {poly_rlst['mse']}, R^2: {poly_rlst['r2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28f55cc-8ac6-4cc2-8be3-01eba7a851a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squaredP, mseP = loo_cv(X_poly, y)\n",
    "print(f\"R^2: {r_squaredP}, MSE: {mseP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3db91e-b07b-44a2-80c4-2cc57862edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's try multiple poly! \n",
    "poly = PolynomialFeatures(3)\n",
    "Xm_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "# drop the last bias column \n",
    "Xm_poly = Xm_poly[:, 1:]\n",
    "Xm_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09d835-b7dd-4337-a857-f3dae2c56da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform single-fold cross validation \n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(Xm_poly, drop_df['admin_rate'], test_size=0.30, random_state=42)\n",
    "\n",
    "# fit to training data \n",
    "m_poly = line_of_best_fit(Xtrain, ytrain)\n",
    "\n",
    "# pass testing data \n",
    "poly_rlst = linreg_predict(Xtest, ytest, m_poly)\n",
    "\n",
    "\n",
    "print(f\"MSE: {poly_rlst['mse']}, R^2: {poly_rlst['r2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbe44d5-4d8d-4f32-97a9-3edc383ff5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOO-CV\n",
    "r_squaredMP, mseMP = loo_cv(Xm_poly, y)\n",
    "print(f\"R^2: {r_squaredMP}, MSE: {mseMP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce77c1cf-57c6-4337-816f-be7504f35c69",
   "metadata": {},
   "source": [
    "# Classifcation Model\n",
    "Thinking of using KNN to classify schools based on region! \n",
    "Steps: \n",
    "1. Apply pca?\n",
    "2. train model\n",
    "3. evaluate model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7670b1-7264-4add-8e7c-19c1feb060c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick out features \n",
    "drop_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3d6a62-8ac2-4c05-92e2-b24d1cbbebae",
   "metadata": {},
   "source": [
    "First try with these features:\n",
    "- admin_rate\n",
    "- school size\n",
    "- avg_sat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b63708-a527-40de-bc80-2bac2aff64e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a01c7-c0a5-4b4d-b089-4737c358e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_feat = ['size', 'admin_rate', 'avg_sat']\n",
    "X = drop_df[k_means_feat]\n",
    "\n",
    "# need to standarize the data! \n",
    "X_scaled = pd.DataFrame()\n",
    "\n",
    "for feat in X.columns:\n",
    "    X_scaled[f'{feat_scaled}'] = ((X[feat] - X[feat].mean()) / X[feat].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87e454c-66bf-4a8b-a06e-12f35d6dc987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find optimum number of cluster\n",
    "\n",
    "sse = [] #SUM OF SQUARED ERROR\n",
    "for k in range(1,11):\n",
    "    km = KMeans(n_clusters=k, random_state=2)\n",
    "    km.fit(X)\n",
    "    sse.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87d51ea-dbea-4ce7-9a1a-cb807f3acaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "g=sns.lineplot(x=range(1,11), y=sse)\n",
    "\n",
    "g.set(xlabel =\"Number of cluster (k)\", \n",
    "      ylabel = \"Sum Squared Error\", \n",
    "      title ='Elbow Method')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502de19c-4422-47e0-bc48-5392e54a0309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELBOW seems to be 3\n",
    "kmeans = KMeans(n_clusters = 3, random_state = 42)\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "# find the cluster centers \n",
    "kmeans.cluster_centers_\n",
    "\n",
    "pred = kmeans.fit_predict(X_scaled)\n",
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfa61d1-c37c-4aa4-b147-9ead336bb5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT OUT THE CLUSTERS! \n",
    "# ------- TURN ALL THIS REPEATING CODE INTO A SINGLE FUNCTION \n",
    "\n",
    "# -- PLOT1\n",
    "plt.figure(figsize=(5,10))\n",
    "plt.subplot(3, 1, 1)\n",
    "\n",
    "plt.scatter(X_scaled['size_scaled'],X_scaled['admin_rate_scaled'],c = pred, cmap=cm.Accent)\n",
    "plt.grid(True)\n",
    "\n",
    "for center in kmeans.cluster_centers_:\n",
    "    center = center[:2] # first two dimensions of the centroid\n",
    "    plt.scatter(center[0],center[1],marker = '^',c = 'red')\n",
    "# look at isolated features! \n",
    "plt.xlabel(\"size\")\n",
    "plt.ylabel(\"admin rate\")\n",
    "\n",
    "\n",
    "# -- PLOT 2 \n",
    "plt.subplot(3, 1, 2)   \n",
    "plt.scatter(X_scaled['size_scaled'],X_scaled['avg_sat_scaled'],c = pred, cmap=cm.Accent)\n",
    "plt.grid(True)\n",
    "for center in kmeans.cluster_centers_:\n",
    "    # center = center[2:4] # --- what is this doing? \n",
    "    center = [center[0], center[2]] \n",
    "    plt.scatter(center[0],center[1],marker = '^',c = 'red')\n",
    "plt.xlabel(\"size\")\n",
    "plt.ylabel(\"avg sat\")\n",
    "\n",
    "# -- PLOT 3 \n",
    "plt.subplot(3, 1, 3)   \n",
    "plt.scatter(X_scaled['admin_rate_scaled'],X_scaled['avg_sat_scaled'],c = pred, cmap=cm.Accent)\n",
    "plt.grid(True)\n",
    "for center in kmeans.cluster_centers_:\n",
    "    center = center[1:] # --- what is this doing? \n",
    "    plt.scatter(center[0],center[1],marker = '^',c = 'red')\n",
    "plt.xlabel(\"admin rate\")\n",
    "plt.ylabel(\"avg sat\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e09f7-9cb4-457f-9821-1ae302cfcfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- checking the standarization \n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cdb1c5-9e32-452a-8229-a1d42432b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def plot_clustering(X):\n",
    "    \"\"\" add in docstring \"\"\"\n",
    "    plt.figure(figsize=(5,10))\n",
    "    \n",
    "    for combo in list(combinations(X.columns, 2)):\n",
    "        plt.subplot(len(X.columns), 1, i) # i doesn't exist here!    \n",
    "        plt.scatter(X_scaled[combo[0]],X_scaled[combo[1]'],c = pred, cmap=cm.Accent)\n",
    "        plt.grid(True)\n",
    "\n",
    "       # --- NEED TO FIGURE THIS PART OUT!              \n",
    "        for center in kmeans.cluster_centers_:\n",
    "            center = center[1:] # --- what is this doing? \n",
    "            plt.scatter(center[0],center[1],marker = '^',c = 'red')\n",
    "            \n",
    "        plt.xlabel(f\"{combo[0]}\")\n",
    "        plt.ylabel(f\"{combo[1]}\")\n",
    "\n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044388fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the code\n",
    "def test_type() -> int, str:\n",
    "    if sat_or_act.lower() == \"sat\":\n",
    "        sat_score = input(\"SAT Score: \")\n",
    "        return sat_score, \"act\"\n",
    "    elif sat_or_act.lower() == \"act\":\n",
    "        act_score = input(\"ACT Score: \")\n",
    "        return act_score, \"sat\"\n",
    "    else:\n",
    "        raise ValueError(f\"{sat_or_act} is an invalid test.\")\n",
    "\n",
    "def ask_for_state(df) -> DataFrame:\n",
    "    state = input(\"What state would you like to look at? (e.g. AZ, MA, ...): \")\n",
    "    \n",
    "    if state.upper() in df['school.state'].unique():\n",
    "        state_df = get_state_df(df, state)\n",
    "        return state_df\n",
    "    else:\n",
    "        raise ValueError(f\"{state} is an invalid state.\")\n",
    "        \n",
    "def get_state_df(df, state) -> DataFrame:\n",
    "    state_dfs = []\n",
    "\n",
    "    for school in df['school.state'].unique():\n",
    "        state_specific_df = df[df['school.state'] == state]\n",
    "    \n",
    "        state_dfs.append(state_specific_df)\n",
    "\n",
    "    state_df = pd.concat(state_dfs, ignore_index=True)\n",
    "    \n",
    "    return state_df\n",
    "\n",
    "def get_reach(state_df, score):\n",
    "    reach_schools = []\n",
    "    school = []\n",
    "    +100\n",
    "    \n",
    "    for index in state_df['latest.admissions.sat_scores.average.overall'].unique():\n",
    "        if df['latest.admissions.sat_scores.average.overall'].unique() >= score+100:\n",
    "            school.append(df['school.name'].unique())\n",
    "            school.append(df['latest.admissions.sat_scores.average.overall'].unique())\n",
    "    \n",
    "def run():\n",
    "    sat_or_act = input(\"What test would you like to use? (ACT or SAT): \")\n",
    "    score, test = test_type()\n",
    "    \n",
    "    print(\"Fetching all college data...\")\n",
    "    all_states = get_all_states_data(key, state_abbreviations)\n",
    "    flattened_data = [school for state_data in all_states for school in state_data]\n",
    "\n",
    "    df = pd.DataFrame(flattened_data)\n",
    "    \n",
    "    state_df = ask_for_state(df)\n",
    "    \n",
    "    \n",
    "    print(state_df)\n",
    "              \n",
    "    \n",
    "        \n",
    "run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd236b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to run the project!\n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
